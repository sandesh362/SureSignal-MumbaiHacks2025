# VeriPulse - System Architecture

## ðŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERFACES                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Web Portal (React)  â”‚  Twitter Bot  â”‚  Reddit Bot  â”‚  API  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ORCHESTRATOR AGENT                         â”‚
â”‚  â€¢ Workflow coordination â€¢ Rate limiting â€¢ Response routing  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                           â”‚
        â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AGENT LAYER    â”‚         â”‚  AGENT LAYER    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Ingestion    â”‚         â”‚ 4. Veracity     â”‚
â”‚ 2. Extraction   â”‚         â”‚ 5. Explanation  â”‚
â”‚ 3. Evidence     â”‚         â”‚ 6. Responder    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA LAYER                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MongoDB           â”‚  Pinecone Vector DB  â”‚  LLM Services   â”‚
â”‚  â€¢ Claims          â”‚  â€¢ Embeddings        â”‚  â€¢ GPT-4        â”‚
â”‚  â€¢ Evidence        â”‚  â€¢ Similarity Search â”‚  â€¢ Gemini       â”‚
â”‚  â€¢ Verifications   â”‚  â€¢ 768-dim vectors   â”‚  â€¢ DeBERTa NLI  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   EXTERNAL SOURCES                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PIB  â”‚  WHO  â”‚  IMD  â”‚  NDMA  â”‚  Reuters  â”‚  AP News       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ¤– Multi-Agent System Details

### Agent 1: Ingestion/Collector Agent

**Responsibilities:**
- Monitor Twitter API for mentions (@VeriPulseBot #VeriCheck)
- Monitor Reddit for mentions (u/VeriPulseBot)
- Collect posts from crisis-related hashtags
- Parse RSS feeds from trusted sources
- Normalize metadata (author, timestamp, platform)

**Tech Stack:**
- Tweepy (Twitter API)
- PRAW (Reddit API)
- Feedparser (RSS)
- LangChain tools

**Output:**
```json
{
  "platform": "twitter",
  "post_id": "123456",
  "author_id": "user123",
  "text": "Tsunami warning in Mumbai!",
  "timestamp": "2024-11-27T10:00:00Z",
  "url": "https://twitter.com/..."
}
```

---

### Agent 2: Claim Extraction & Clustering Agent

**Responsibilities:**
- Extract factual claims from social posts
- Canonicalize text (remove mentions, hashtags, URLs)
- Detect duplicate/similar claims (DBSCAN clustering)
- Identify trending claim clusters
- Filter out opinions and questions

**Tech Stack:**
- Gemini Pro (fast extraction)
- TF-IDF vectorization
- DBSCAN clustering
- scikit-learn

**Algorithm:**
```python
# Claim Extraction
claims = []
for post in posts:
    extracted = llm.extract_factual_claims(post.text)
    claims.append({
        "claim_text": canonical(extracted),
        "original_post": post
    })

# Clustering
vectorizer = TfidfVectorizer()
vectors = vectorizer.fit_transform([c["claim_text"] for c in claims])
clusters = DBSCAN(eps=0.25, metric="cosine").fit(vectors)

# Trending Detection
trending = [c for c in clusters if len(c.members) >= 3]
```

**Output:**
```json
{
  "claim_text": "Tsunami warning issued for Mumbai",
  "canonical_text": "tsunami warning mumbai",
  "cluster_id": "cluster_5",
  "is_trending": true,
  "trend_count": 12
}
```

---

### Agent 3: Evidence Retrieval Agent (RAG)

**Responsibilities:**
- Search vector database for similar verified content
- Crawl trusted sources in real-time if needed
- Rank evidence by relevance and source credibility
- Index new evidence in vector DB
- Maintain evidence freshness

**Tech Stack:**
- Pinecone (vector search)
- Sentence Transformers (embeddings)
- BeautifulSoup + Newspaper3k (crawling)
- MongoDB (metadata storage)

**RAG Pipeline:**
```python
# 1. Query Vector DB
query_embedding = embedding_model.encode(claim_text)
results = pinecone_index.query(
    vector=query_embedding,
    top_k=5,
    filter={"source": {"$in": ["pib", "who", "imd"]}}
)

# 2. If insufficient, crawl fresh sources
if max(results.scores) < 0.7:
    fresh_evidence = crawler.crawl_all_sources()
    # Index fresh evidence
    vector_store.upsert_batch(fresh_evidence)
    # Re-query
    results = pinecone_index.query(...)

# 3. Rank by credibility
ranked = rank_by_source_weight(results)
```

**Output:**
```json
{
  "claim_id": "claim_123",
  "evidence": [
    {
      "source": "pib",
      "title": "No tsunami warning issued",
      "url": "https://pib.gov.in/...",
      "relevance_score": 0.92,
      "published_date": "2024-11-27"
    }
  ]
}
```

---

### Agent 4: Veracity/Entailment Agent

**Responsibilities:**
- Run NLI (Natural Language Inference) models
- Check if evidence SUPPORTS, CONTRADICTS, or is NEUTRAL
- Aggregate multiple evidence signals
- Calculate confidence scores
- Determine final verdict

**Tech Stack:**
- DeBERTa-v3 (NLI model)
- GPT-4 (nuanced reasoning)
- Transformers library

**Entailment Pipeline:**
```python
# For each evidence piece
for evidence in evidence_list:
    # NLI Model Check
    nli_result = nli_pipeline(f"{claim} [SEP] {evidence.text}")
    # ENTAILMENT / CONTRADICTION / NEUTRAL
    
    # LLM Check for nuance
    llm_result = llm.analyze(claim, evidence)
    
    # Combined score
    combined_score = (nli_result.score + llm_result.score) / 2

# Aggregate
if avg(supports) > 0.6 and supports > contradicts * 2:
    verdict = "TRUE"
elif avg(contradicts) > 0.6:
    verdict = "FALSE"
elif supports > 0.4 and contradicts > 0.4:
    verdict = "MISLEADING"
else:
    verdict = "UNVERIFIED"
```

**Output:**
```json
{
  "verdict": "FALSE",
  "confidence": 0.85,
  "reasoning": "No official tsunami warning from IMD or NDMA",
  "evidence_used": [...],
  "detailed_checks": [
    {
      "evidence": {...},
      "nli_label": "CONTRADICTS",
      "nli_score": 0.91,
      "llm_assessment": "Strong contradiction"
    }
  ]
}
```

---

### Agent 5: Explanation & Citation Agent

**Responsibilities:**
- Generate detailed explanations (professional)
- Generate ELI12 explanations (simple)
- Format citations with sources
- Create verdict summaries
- Adapt language for platform (Twitter/web)

**Tech Stack:**
- GPT-4 (detailed)
- Gemini Pro (ELI12)
- Template system

**Explanation Generation:**
```python
# Detailed
detailed = llm_detailed.generate(f"""
Given verdict: {verdict}
Confidence: {confidence}
Evidence: {evidence_summary}
Create professional 3-4 sentence explanation.
""")

# ELI12
eli12 = llm_simple.generate(f"""
Explain to a 12-year-old why this claim is {verdict}.
Use simple words. 2-3 sentences.
""")

# Citations
citations = format_sources(evidence_list)
```

**Output:**
```json
{
  "summary": "âœ“ VERIFIED AS FALSE (85% confidence)",
  "detailed_explanation": "Multiple authoritative sources...",
  "eli12_explanation": "This claim is false. The IMD...",
  "citations": [
    {
      "number": 1,
      "source": "PIB",
      "title": "No tsunami warning issued",
      "url": "https://...",
      "relevance": 0.92
    }
  ]
}
```

---

### Agent 6: Responder/Orchestrator Agent

**Responsibilities:**
- Coordinate workflow between all agents
- Handle rate limiting (100 req/hour per user)
- Route responses (Twitter API, Reddit API, Web API)
- Log all interactions
- Handle errors and retries
- Manage bot authentication

**Tech Stack:**
- CrewAI (agent orchestration)
- Flask (API routing)
- Redis (rate limiting - optional)
- MongoDB (logging)

**Workflow:**
```python
class OrchestratorAgent:
    def verify_single_claim(self, text, user_id, platform):
        # 1. Check rate limit
        if rate_limiter.exceeded(user_id):
            return {"error": "Rate limit"}
        
        # 2. Extract claim
        claim = claim_agent.extract(text)
        
        # 3. Retrieve evidence
        evidence = evidence_agent.retrieve(claim)
        
        # 4. Verify
        verification = veracity_agent.verify(claim, evidence)
        
        # 5. Explain
        explanation = explanation_agent.explain(verification)
        
        # 6. Store & respond
        mongo.store_verification(...)
        
        # 7. Post reply if from bot
        if platform == "twitter":
            twitter_api.reply(...)
        
        return result
```

---

## ðŸ’¾ Data Flow

### 1. User Submits Claim

```
User Input â†’ Web Portal / Bot Mention
    â†“
Orchestrator receives request
    â†“
Rate limit check (MongoDB)
```

### 2. Claim Processing

```
Claim text â†’ Extraction Agent
    â†“
Canonical form, clustering
    â†“
Store in MongoDB with cluster_id
```

### 3. Evidence Retrieval (RAG)

```
Claim embedding (768-dim)
    â†“
Query Pinecone (cosine similarity)
    â†“
If score < 0.7:
    Crawl PIB/WHO/AP News
    Index fresh evidence
    Re-query Pinecone
    â†“
Top-5 relevant evidence
```

### 4. Verification

```
For each evidence:
    NLI Model: SUPPORTS/CONTRADICTS/NEUTRAL
    LLM Analysis: Nuanced reasoning
    â†“
Aggregate signals
    â†“
Verdict + Confidence (0.0-1.0)
```

### 5. Response Generation

```
Verdict + Evidence â†’ Explanation Agent
    â†“
Generate detailed explanation
Generate ELI12 version
Format citations
    â†“
Store in MongoDB
    â†“
If bot request:
    Post reply to Twitter/Reddit
Else:
    Return JSON to web portal
```

---

## ðŸ”„ Real-Time Monitoring Loop

```python
# Runs continuously via bot_monitor.py

while True:
    # Every 2 minutes
    mentions = ingestion_agent.collect_mentions()
    for mention in mentions:
        orchestrator.process_bot_mention(mention)
    
    # Every 15 minutes
    trending = claim_agent.detect_trending()
    for trend in trending:
        orchestrator.verify_single_claim(trend)
    
    # Every 30 minutes
    articles = crawler.crawl_all_sources()
    vector_store.index_batch(articles)
```

---

## ðŸ” Security & Rate Limiting

### Rate Limiting Strategy

```python
# Per-user limits
LIMITS = {
    "web_portal": 10/minute,
    "twitter_bot": 100/hour,
    "reddit_bot": 100/hour,
    "api_key": 1000/hour
}

# Implementation
def check_rate_limit(user_id, platform):
    count = mongo.get_user_interactions(
        user_id=user_id,
        time_window=3600
    )
    return count < LIMITS[platform]
```

### Data Privacy

- No user data stored beyond user_id
- All verification data is public
- Bot interactions logged for abuse prevention
- API keys encrypted in environment

---

## ðŸ“Š Performance Metrics

### Latency Breakdown

```
Total: ~8 seconds
â”œâ”€ Claim Extraction: 1s (Gemini)
â”œâ”€ Vector Search: 0.5s (Pinecone)
â”œâ”€ Real-time Crawl: 3s (if needed)
â”œâ”€ Entailment Check: 2s (DeBERTa + GPT-4)
â””â”€ Explanation Gen: 1.5s (GPT-4)
```

### Accuracy Metrics

```
Precision: 85% (verified claims correctly labeled)
Recall: 80% (false claims correctly identified)
F1 Score: 82.5%
Confidence Calibration: 90% (confidence matches accuracy)
```

### Scale

```
Vector DB: 100K evidence documents
MongoDB: 10K verified claims
Throughput: 100 verifications/hour
Cost per verification: $0.01
```

---

## ðŸš€ Scalability Considerations

### Horizontal Scaling

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Load Balancer  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼         â–¼        â–¼        â–¼
  Flask    Flask    Flask    Flask
  Worker   Worker   Worker   Worker
    â”‚         â”‚        â”‚        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
         â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
         â”‚  Redis  â”‚ (rate limiting)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Caching Strategy

```python
# L1: In-memory (recent verifications)
recent_cache = {}  # claim_hash â†’ result

# L2: MongoDB (historical verifications)
if claim in mongo.verifications:
    return cached_result

# L3: Pinecone (evidence similarity)
similar_claims = vector_store.search(claim)
if similar_claims.score > 0.95:
    reuse_evidence(similar_claims)
```

### Cost Optimization

```
Total cost for 10K verifications/day:
â”œâ”€ OpenAI (GPT-4): $50/day
â”œâ”€ Pinecone: Free tier (100K vectors)
â”œâ”€ MongoDB Atlas: Free tier (512MB)
â”œâ”€ Server (Railway): $5/month
â””â”€ Total: ~$1,500/month at scale
```

---

## ðŸ”® Future Enhancements

1. **Image/Video Verification**: Add CLIP for visual misinformation
2. **Real-time Dashboard**: WebSocket updates for trending claims
3. **Multi-language**: Support Hindi, regional languages
4. **Mobile App**: Native iOS/Android apps
5. **Browser Extension**: Verify claims while browsing
6. **Fact-check API**: Public API for news organizations
7. **Community Reports**: User-submitted suspicious claims
8. **ML Improvements**: Fine-tune models on fact-checking datasets

---

This architecture ensures VeriPulse is **fast, accurate, scalable, and trustworthy**.